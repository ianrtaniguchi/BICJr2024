Mais conhecidos como jailbreaks ou fugas de prisão em tradução livre, são conjuntos de código em linguagem natural que auxiliam o usuário do chatbot a conseguir uma resposta mais precisa e sem limitações éticas.

No arquivo Prompts existentes para o chat gpt, você encontrará numerosos prompts de jailbreak para chat gpt 3.5 como exemplo
